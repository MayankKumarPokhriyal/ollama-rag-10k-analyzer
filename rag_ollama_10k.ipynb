{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23108a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Checking environment...\n",
      " faiss - Installed\n",
      " sentence_transformers - Installed\n",
      " pypdf - Installed\n",
      " langchain - Installed\n",
      " langchain_ollama - Installed\n",
      "\n",
      "Ollama installed. Available models:\n",
      "NAME             ID              SIZE      MODIFIED          \n",
      "llama3:latest    365c0bd3c000    4.7 GB    About an hour ago\n",
      "Found PDF: tsla-20241231.pdf\n",
      "\n",
      "Environment check complete.\n"
     ]
    }
   ],
   "source": [
    "import subprocess, importlib.util, os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\" Checking environment...\")\n",
    "\n",
    "# Check major libraries\n",
    "packages = [\n",
    "    \"faiss\", \"sentence_transformers\", \"pypdf\", \"langchain\", \"langchain_ollama\"\n",
    "]\n",
    "for pkg in packages:\n",
    "    spec = importlib.util.find_spec(pkg)\n",
    "    print(f\" {pkg} - {'Installed' if spec else 'Missing'}\")\n",
    "\n",
    "# Check Ollama installation\n",
    "try:\n",
    "    output = subprocess.check_output([\"ollama\", \"list\"]).decode(\"utf-8\").strip()\n",
    "    print(\"\\nOllama installed. Available models:\")\n",
    "    print(output)\n",
    "except Exception as e:\n",
    "    print(f\" Ollama not found or not running: {e}\")\n",
    "\n",
    "# Check PDF file\n",
    "data_dir = Path(\"data\")\n",
    "pdfs = list(data_dir.glob(\"*.pdf\"))\n",
    "if not pdfs:\n",
    "    print(\"No PDF found in data/. Please add your 10-K PDF file.\")\n",
    "else:\n",
    "    print(f\"Found PDF: {pdfs[0].name}\")\n",
    "\n",
    "print(\"\\nEnvironment check complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af701b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded PDF: tsla-20241231.pdf\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pypdf import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import ChatOllama\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "STORE_DIR = Path(\"store\")\n",
    "STORE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "PDF_PATH = next(DATA_DIR.glob(\"*.pdf\"), None)\n",
    "if PDF_PATH is None:\n",
    "    raise SystemExit(\"Please add a 10-K PDF inside 'data/' before running.\")\n",
    "\n",
    "print(f\" Loaded PDF: {PDF_PATH.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a39a5715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from PDF...\n",
      "Extracted 399K characters of text.\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    print(\"Extracting text from PDF...\")\n",
    "    reader = PdfReader(str(pdf_path))\n",
    "    text = \"\"\n",
    "    for i, page in enumerate(reader.pages):\n",
    "        try:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "        except Exception:\n",
    "            print(f\"Skipped page {i}\")\n",
    "    print(f\"Extracted {len(text)//1000}K characters of text.\")\n",
    "    return text\n",
    "\n",
    "text = extract_text_from_pdf(PDF_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "182d6a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 549 chunks.\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(text, chunk_size=800, overlap=100):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)\n",
    "    chunks = splitter.split_text(text)\n",
    "    print(f\"Created {len(chunks)} chunks.\")\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18d04aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings and FAISS index...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204c9eb5200641a291ed30e6d22d6927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index built and saved with 549 vectors.\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating embeddings and FAISS index...\")\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = model.encode(chunks, convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "# Normalize for cosine similarity\n",
    "embeddings = embeddings / (np.linalg.norm(embeddings, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "# Save for reusability\n",
    "faiss.write_index(index, str(STORE_DIR / \"faiss.index\"))\n",
    "with open(STORE_DIR / \"chunks.pkl\", \"wb\") as f:\n",
    "    pickle.dump(chunks, f)\n",
    "\n",
    "print(f\"FAISS index built and saved with {index.ntotal} vectors.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a400377c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manufacturing, marketing, sales and delivery, service, installation, technology and support personnel, especially to support our\n",
      "planned high-volume product sales, market and geographical expansion and technological innovations. If we are not successful in\n",
      "managing these risks, our business, financial condition and operating results may be harmed.\n",
      "Employees may leave Tesla or choose other employer\n"
     ]
    }
   ],
   "source": [
    "def retrieve(query, k=5):\n",
    "    q_vec = model.encode([query], convert_to_numpy=True)\n",
    "    q_vec = q_vec / (np.linalg.norm(q_vec, axis=1, keepdims=True) + 1e-12)\n",
    "    D, I = index.search(q_vec, k)\n",
    "    return [chunks[i] for i in I[0]]\n",
    "\n",
    "# quick test\n",
    "print(retrieve(\"What are Tesla's main risks?\")[0][:400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56ccb036",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3\", temperature=0.2)\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert financial analyst.\n",
    "Answer using ONLY the provided 10-K context.\n",
    "If not found, reply 'Not available in the 10-K report.'\n",
    "Always cite [source: company 10-K].\"\"\"\n",
    "\n",
    "def answer(query, k=5):\n",
    "    retrieved = retrieve(query, k)\n",
    "    context = \"\\n\\n\".join(retrieved)\n",
    "    prompt = f\"{SYSTEM_PROMPT}\\n\\nContext:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    resp = llm.invoke(prompt)\n",
    "    return resp.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5999aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50c765558b249b58b0c870e8068601a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='Question:', layout=Layout(width='70%'), placeholder='Type your ques…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple interactive question–answer box for Jupyter / VS Code\n",
    "from ipywidgets import Text, Button, VBox, Output\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "question_box = Text(\n",
    "    value='',\n",
    "    placeholder='Type your question here...',\n",
    "    description='Question:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '70%'}\n",
    ")\n",
    "\n",
    "ask_button = Button(description='Ask', button_style='info')\n",
    "exit_button = Button(description='Exit', button_style='danger')\n",
    "output_area = Output()\n",
    "\n",
    "def on_ask_clicked(b):\n",
    "    q = question_box.value.strip()\n",
    "    if not q:\n",
    "        with output_area:\n",
    "            clear_output()\n",
    "            display(Markdown(\"Please enter a question.\"))\n",
    "        return\n",
    "    if q.lower() in ['exit', 'quit']:\n",
    "        on_exit_clicked(b)\n",
    "        return\n",
    "\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        display(Markdown(f\"### Question: {q}\"))\n",
    "        display(Markdown(\"Processing...\"))\n",
    "\n",
    "    try:\n",
    "        ans = answer(q)\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            display(Markdown(f\"### Question: {q}\"))\n",
    "            display(Markdown(f\"**Answer:**\\n\\n{ans}\\n\\n---\"))\n",
    "    except Exception as e:\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            display(Markdown(f\"Error: {e}\"))\n",
    "    question_box.value = ''\n",
    "\n",
    "def on_exit_clicked(b):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        display(Markdown(\"Session ended. You can close this cell or rerun it later.\"))\n",
    "\n",
    "ask_button.on_click(on_ask_clicked)\n",
    "exit_button.on_click(on_exit_clicked)\n",
    "\n",
    "display(VBox([question_box, ask_button, exit_button, output_area]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290bba2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
